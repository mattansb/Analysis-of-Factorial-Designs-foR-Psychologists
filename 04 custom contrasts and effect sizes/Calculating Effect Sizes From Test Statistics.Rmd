---
title: "Calculating (standardized) Effect Sizes"
subtitle: "From Test Statistics"
output: 
  ioslides_presentation:
    widescreen: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Percent Variance Explained | Really *Partial* Percent Variance Explained

##

These are effects sizes that give a Signal to Noise (S/N) ratio with the signal = effect, and noise = error.

Overall, the idea is to estimate Effect / (Effect + Error).

## Partial Eta Squared

Given that:

$$
\eta^2_p = \frac{SS_{effect}}{SS_{effect} + SS_{error}}
$$

And that 

$$
F = \frac{SS_{effect} / df_1}{SS_{error} / df2}
$$

## {.smaller}

$\eta^2_p$ can be approximated by:

$$
\eta^2_p = \frac{F*df_1}{F*df_1 + df_2}
$$
$$
\eta^2_p = \frac{t^2}{t^2 + df}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::F_to_eta2()
effectsize::t_to_eta2()
```

<sub>(Formula from Friedman (1982) Simplified Determinations of Statistical Power, Magnitude of Effect and Research Sample Sizes. https://doi.org/10.1177%2F001316448204200214)</sub>

## Adjusted Partial Eta Squared = Partial Epsilon Squared

Given that:

$$
\hat{\eta}^2_P=\epsilon^2_p = \frac{SS_{effect}-df_1\times MS_{error}}{SS_{effect} + SS_{error}}
$$

And that 

$$
F = \frac{SS_{effect} / df_1}{SS_{error} / df2}
$$

## {.smaller}

$\hat{\eta}^2_P=\epsilon^2_p$ can be approximated by:

$$
\hat{\eta}^2_P=\epsilon^2_p = \frac{(F-1)*df_1}{F*df_1 + df_2}
$$
$$
\hat{\eta}^2_P=\epsilon^2_p = \frac{t^2-1}{t^2 + df}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::F_to_epsilon2()
effectsize::t_to_epsilon2()
effectsize::F_to_eta2_adj()
effectsize::t_to_eta2_adj()
```

<sub>Formula from Mordkoff (2019) A Simple Method for Removing Bias From a Popular Measure of Standardized Effect Size: Adjusted Partial Eta Squared. https://doi.org/10.1177%2F2515245919855053</sub>

## Partial Omega Squared

Given that:

$$
\omega^2_p = \frac{SS_{effect}-df_1\times MS_{error}}{SS_{effect} + SS_{error}+MS_w}
$$

And that 

$$
F = \frac{SS_{effect} / df_1}{SS_{error} / df2}
$$

## {.smaller}

$\omega^2_p$ can be approximated by:

$$
\omega^2_p = \frac{(F-1)*df_1}{F*df_1 + df_2 +1}
$$
$$
\omega^2_p = \frac{t^2-1}{t^2 + df+1}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::F_to_omega2()
effectsize::t_to_omega2()
```

<sub>Formula from Lakens & Albers (2018) When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias https://doi-org.ezproxy.bgu.ac.il/10.1016/j.jesp.2017.09.004 & http://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html</sub>


# Standardized Differences | AKA *Cohen's d*

##

This effect size represents the standardized distance between two means (or two weighted means).

The idea is to estimate $(X_1 - X_2) / S$.

## Cohen's d

Given that:

$$
\text{Cohen's } d = \frac{\bar{x}_1-\bar{x}_2}{\sqrt{s_{pooled}}}
$$

And that 

$$
t_{contrast} = \sqrt{\frac{SS_{contrast}}{MSE}}
$$

## {.smaller}

Then it is possible to proove that in a **between-subjects design**, *Cohen's d* can be approximated by:

$$
\text{Cohen's } d = \frac{2\times t}{\sqrt{df}}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::t_to_d()
```

<sub>Formula for between-subjects design from Wolf, F. M. (1986). Meta-analysis: Quantitative methods for research synthesis (Vol. 59). Sage. Chapter 3 tables 8-9 page 35</sub>


## {.smaller}

... and it is possible to proove that in a **within-subjects design**, *Cohen's d* can be approximated by:

$$
\text{Cohen's } d_z = \frac{t}{\sqrt{df}}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::t_to_d(pooled = TRUE)
```

<sub>Formula for within-subjects desing from Rosenthal, R. (1991).Meta-analytic procedures for social research. Newbury Park, CA: SAGE Publications, Incorporated.</sub>

<sub>Read more at Lakens (2013) Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs https://www.psychometrica.de/effect_size.html</sub>

# Alerting Correlation | $r^2_{alerting}$

## 

Given that

$$
r^2_{alerting} = \frac{SS_{contrast}}{SS_{effect}}
$$

$$
t_{contrast} = \sqrt{\frac{SS_{contrast}}{MSE}}
$$

$$
F_{effect} = \frac{SS_{effect} / df_1}{MSE}
$$

## {.smaller}

Then $r^2_{alerting}$ can be approximated by:

$$
r^2_{alerting} = \frac{t_{contrast}^2}{F_{effect} \times df_1}
$$

In `R`:
```{r}
t_and_F_to_r2alerting <- function(t, f, df) {
    t ^ 2 / (f * df)
}
```

**Use this method carefully...**

- This approximation is true ***ONLY*** for models assuming homoscedasticity (for  between subject factors) and sphericity (for within subject factors) - where t's and F's MSE are equal. In all other cases, you would need to calculate the SSs manually.

- Things get a bit trickier with interaction-contrasts... No easy solution there...

<sub>Formula from Rosnow, et al. (2000) Contrasts and Correlations in Effect-Size Estimation. https://doi.org/10.1111%2F1467-9280.00287</sub>
