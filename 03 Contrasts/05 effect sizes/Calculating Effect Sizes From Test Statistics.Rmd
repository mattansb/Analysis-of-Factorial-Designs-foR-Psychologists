---
title: "Calculating (standardized) Effect Sizes"
subtitle: "From Test Statistics"
output: 
  ioslides_presentation:
    widescreen: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##

See [*Effect Size from Test Statistics* vignette](https://easystats.github.io/effectsize/articles/from_test_statistics.html) in the `effectsize` package.

# Percent Variance Explained | Really *Partial* Percent Variance Explained

##

These are effects sizes that give a Signal to Noise (S/N) ratio with the signal = effect, and noise = error.

Overall, the idea is to estimate Effect / (Effect + Error).

## Partial Eta Squared

Given that:

$$
\eta^2_p = \frac{SS_{effect}}{SS_{effect} + SS_{error}}
$$

And that 

$$
F = \frac{SS_{effect} / df_1}{SS_{error} / df2}
$$

## {.smaller}

$\eta^2_p$ can be approximated by:

$$
\eta^2_p = \frac{F*df_1}{F*df_1 + df_2}
$$
$$
\eta^2_p = \frac{t^2}{t^2 + df}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::F_to_eta2()
effectsize::t_to_eta2()
```

<sub>(Formula from Friedman (1982) Simplified Determinations of Statistical Power, Magnitude of Effect and Research Sample Sizes. https://doi.org/10.1177%2F001316448204200214)</sub>

## Adjusted Partial Eta Squared = Partial Epsilon Squared

$\epsilon^2_p$ is analogous to $R^2_{adjusted}$ ([Allen, 2017, pp. 382](https://doi.org/10.1142/q0019)).

Given that:

$$
\hat{\eta}^2_P=\epsilon^2_p = \frac{SS_{effect}-df_1\times MS_{error}}{SS_{effect} + SS_{error}}
$$

And that 

$$
F = \frac{SS_{effect} / df_1}{SS_{error} / df2}
$$

## {.smaller}

$\hat{\eta}^2_P=\epsilon^2_p$ can be approximated by:

$$
\hat{\eta}^2_P=\epsilon^2_p = \frac{(F-1)*df_1}{F*df_1 + df_2}
$$
$$
\hat{\eta}^2_P=\epsilon^2_p = \frac{t^2-1}{t^2 + df}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::F_to_epsilon2()
effectsize::t_to_epsilon2()
effectsize::F_to_eta2_adj()
effectsize::t_to_eta2_adj()
```

<sub>Formula from Mordkoff (2019) A Simple Method for Removing Bias From a Popular Measure of Standardized Effect Size: Adjusted Partial Eta Squared. https://doi.org/10.1177%2F2515245919855053</sub>

## Partial Omega Squared

Given that:

$$
\omega^2_p = \frac{SS_{effect}-df_1\times MS_{error}}{SS_{effect} + SS_{error}+MS_{error}}
$$

And that 

$$
F = \frac{SS_{effect} / df_1}{SS_{error} / df2}
$$

## {.smaller}

$\omega^2_p$ can be approximated by:

$$
\omega^2_p = \frac{(F-1)*df_1}{F*df_1 + df_2 +1}
$$
$$
\omega^2_p = \frac{t^2-1}{t^2 + df+1}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::F_to_omega2()
effectsize::t_to_omega2()
```

<sub>Formula from Lakens & Albers (2018) When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias https://doi.org/10.1016/j.jesp.2017.09.004 & http://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html</sub>


## Partial Cohen's f

Given that:

$$
f_p = \sqrt{\frac{\eta^2_p}{1-\eta^2_p}}
$$

And... We already saw how to get $\eta^2_p$ from $F$.

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::F_to_f()
effectsize::t_to_f()
```

Cohen's $f$ is similar to Cohen's $d$ in the context of more than 2 means.

Speaking of which...

# Standardized Differences | AKA *Cohen's d*

##

This effect size represents the standardized distance between two means (or two weighted means).

The idea is to estimate $(X_1 - X_2) / S$.

## Cohen's d

Given that:

$$
\text{Cohen's } d = \frac{\bar{x}_1-\bar{x}_2}{\sqrt{s_{pooled}}}
$$

And that 

$$
t_{contrast} = \sqrt{\frac{SS_{contrast}}{MSE}}
$$

## {.smaller}

Then it is possible to prove that in a **between-subjects design**, *Cohen's d* can be approximated by:

$$
\text{Cohen's } d = \frac{2\times t}{\sqrt{df}}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::t_to_d()
```

<sub>Formula for between-subjects design from Wolf, F. M. (1986). Meta-analysis: Quantitative methods for research synthesis (Vol. 59). Sage. Chapter 3 tables 8-9 page 35</sub>


## {.smaller}

... and it is possible to prove that in a **within-subjects design**, *Cohen's d* can be approximated by:

$$
\text{Cohen's } d_z = \frac{t}{\sqrt{df}}
$$

in `R` this can be done with:

```{r, eval=FALSE}
effectsize::t_to_d(paired = TRUE)
```

<sub>Formula for within-subjects design from Rosenthal, R. (1991).Meta-analytic procedures for social research. Newbury Park, CA: SAGE Publications, Incorporated.</sub>  

<sub>Read more at Lakens (2013) Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs https://www.psychometrica.de/effect_size.html</sub>

# Alerting Correlation | $r^2_{alerting}$

## 

Given that

$$
r^2_{alerting} = \frac{SS_{contrast}}{SS_{effect}}
$$

$$
t_{contrast} = \sqrt{\frac{SS_{contrast}}{MSE}}
$$

$$
F_{effect} = \frac{SS_{effect} / df_1}{MSE}
$$

## {.smaller}

Then $r^2_{alerting}$ can be approximated by:

$$
r^2_{alerting} = \frac{t_{contrast}^2}{F_{effect} \times df_1}
$$

In `R`:
```{r, eval=FALSE}
t_and_F_to_r2alerting <- function(t, f, df) {
    t ^ 2 / (f * df)
}
```

**Use this method carefully...**

- This approximation is true ***ONLY*** when $MSE_{\text{effect}}$ and $MSE_{\text{contrast}}$ are the same. When is this true? When homoscedasticity (for  between subject factors) and sphericity (for within subject factors) are assumed. In all other cases, you would need to calculate the SSs manually.  

- Things get very tricky with interaction-contrasts... No easy solution there...

<sub>Formula from Rosnow, et al. (2000) Contrasts and Correlations in Effect-Size Estimation. https://doi.org/10.1111%2F1467-9280.00287</sub>
